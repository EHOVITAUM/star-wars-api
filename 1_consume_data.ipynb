{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### consumindo dados da api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_swapi_data(endpoint):\n",
    "    \"\"\"Função para consumir a API do Star Wars.\"\"\"\n",
    "    url = f\"https://swapi.dev/api/{endpoint}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None  # Retorna None caso o status não seja 200\n",
    "\n",
    "# Dicionário para armazenar os dados de cada categoria\n",
    "swapi_data = {\n",
    "    \"people\": [],\n",
    "    \"planets\": [],\n",
    "    \"films\": [],\n",
    "    \"species\": [],\n",
    "    \"vehicles\": [],\n",
    "    \"starships\": []\n",
    "}\n",
    "\n",
    "# Função para coletar os dados até encontrar 10 erros 404 consecutivos\n",
    "def collect_data(category):\n",
    "    id_ = 1  # Começamos do ID 1\n",
    "    not_found_count = 0  # Contador de erros 404 consecutivos\n",
    "\n",
    "    while not_found_count < 10:  # Encerra apenas após 10 erros 404 seguidos\n",
    "        data = get_swapi_data(f\"{category}/{id_}\")\n",
    "\n",
    "        if data is None:\n",
    "            not_found_count += 1  # Incrementa contador de 404 consecutivos\n",
    "            print(f\"{category.capitalize()} ID {id_} não encontrado. Contagem de 404: {not_found_count}\")\n",
    "        else:\n",
    "            not_found_count = 0  # Reseta o contador se encontrar um ID válido\n",
    "            swapi_data[category].append(data)\n",
    "\n",
    "        id_ += 1  # Avança para o próximo ID\n",
    "    \n",
    "    print(f\"Fim da coleta para {category}! Total coletado: {len(swapi_data[category])}\")\n",
    "\n",
    "# Coletar dados para cada categoria\n",
    "categories = [\"people\", \"planets\", \"films\", \"species\", \"vehicles\", \"starships\"]\n",
    "\n",
    "for category in categories:\n",
    "    collect_data(category)\n",
    "\n",
    "# Convertendo para DataFrames para facilitar a análise\n",
    "df_people = pd.DataFrame(swapi_data[\"people\"])\n",
    "df_planets = pd.DataFrame(swapi_data[\"planets\"])\n",
    "df_films = pd.DataFrame(swapi_data[\"films\"])\n",
    "df_species = pd.DataFrame(swapi_data[\"species\"])\n",
    "df_vehicles = pd.DataFrame(swapi_data[\"vehicles\"])\n",
    "df_starships = pd.DataFrame(swapi_data[\"starships\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conferindo dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people\n",
    "# df_planets\n",
    "# df_films\n",
    "# df_species\n",
    "# df_vehicles\n",
    "# df_starships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformando dados, agragando dados interessantes em um DF só."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Carregar os DataFrames\n",
    "df_people_enriched = df_people\n",
    "\n",
    "# Função para substituir URLs por nomes\n",
    "def substituir_urls(df_base, coluna, df_mapeamento, chave, valor):\n",
    "    mapeamento = dict(zip(df_mapeamento[chave], df_mapeamento[valor]))\n",
    "    df_base[coluna] = df_base[coluna].apply(lambda x: ', '.join([mapeamento.get(url, url) for url in ast.literal_eval(x)]) if isinstance(x, str) else x)\n",
    "\n",
    "# Substituir homeworld (planeta)\n",
    "df_people_enriched['homeworld'] = df_people_enriched['homeworld'].map(dict(zip(df_planets['url'], df_planets['name'])))\n",
    "\n",
    "# Substituir films (filmes)\n",
    "substituir_urls(df_people_enriched, 'films', df_films, 'url', 'title')\n",
    "\n",
    "# Substituir species (espécies)\n",
    "substituir_urls(df_people_enriched, 'species', df_species, 'url', 'name')\n",
    "\n",
    "# Substituir vehicles (veículos)\n",
    "substituir_urls(df_people_enriched, 'vehicles', df_vehicles, 'url', 'name')\n",
    "\n",
    "# Substituir starships (naves)\n",
    "substituir_urls(df_people_enriched, 'starships', df_starships, 'url', 'name')\n",
    "\n",
    "# Criar mapeamento de personagens por filme\n",
    "film_characters_map = {row['url']: ast.literal_eval(row['characters']) for _, row in df_films.iterrows()}\n",
    "\n",
    "# Criar dicionário para mapear URLs de personagens para seus nomes\n",
    "character_name_map = dict(zip(df_people_enriched['url'], df_people_enriched['name']))\n",
    "\n",
    "# Criar nova coluna com os personagens que apareceram nos mesmos filmes\n",
    "def obter_colegas(films, self_url):\n",
    "    if isinstance(films, str):\n",
    "        films_list = films.split(', ')  # Já está no formato de nomes de filmes\n",
    "        personagens = set()\n",
    "        for film in df_films[df_films['title'].isin(films_list)]['characters']:\n",
    "            personagens.update(ast.literal_eval(film))\n",
    "        personagens.discard(self_url)  # Remover o próprio personagem\n",
    "        return ', '.join([character_name_map.get(url, url) for url in personagens])\n",
    "    return \"\"\n",
    "\n",
    "df_people_enriched['characters_met'] = df_people_enriched.apply(lambda row: obter_colegas(row['films'], row['url']), axis=1)\n",
    "\n",
    "# Salvar o resultado final\n",
    "df_people_enriched.to_csv('people_enriquecido.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people_enriched.columns\n",
    "df_people_enriched.to_json('star_wars_characters.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
